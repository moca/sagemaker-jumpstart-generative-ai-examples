{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d217d2b1-1aad-4ad7-a0f1-34eb05f76108",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "import sagemaker as sm\n",
    "\n",
    "from sagemaker import script_uris\n",
    "from sagemaker import image_uris\n",
    "from sagemaker import model_uris\n",
    "from sagemaker import hyperparameters\n",
    "\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "\n",
    "ROLE = sm.get_execution_role()\n",
    "REGION = boto3.Session().region_name\n",
    "session = sm.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8782a4c8-fb21-48e7-9785-937e52eb494b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: img/.ipynb_checkpoints/dataset_info-Copy1-checkpoint.json to s3://sagemaker-eu-central-1-106877348565/js-input/artmoca/.ipynb_checkpoints/dataset_info-Copy1-checkpoint.json\n",
      "upload: img/.ipynb_checkpoints/dataset_info-checkpoint.json to s3://sagemaker-eu-central-1-106877348565/js-input/artmoca/.ipynb_checkpoints/dataset_info-checkpoint.json\n",
      "upload: img/artmoca_1.jpeg to s3://sagemaker-eu-central-1-106877348565/js-input/artmoca/artmoca_1.jpeg\n",
      "upload: img/artmoca_3.jpeg to s3://sagemaker-eu-central-1-106877348565/js-input/artmoca/artmoca_3.jpeg\n",
      "upload: img/dataset_info.json to s3://sagemaker-eu-central-1-106877348565/js-input/artmoca/dataset_info.json\n",
      "upload: img/artmoca_2.jpeg to s3://sagemaker-eu-central-1-106877348565/js-input/artmoca/artmoca_2.jpeg\n",
      "upload: img/artmoca_4.jpeg to s3://sagemaker-eu-central-1-106877348565/js-input/artmoca/artmoca_4.jpeg\n",
      "upload: img/artmoca_5.jpeg to s3://sagemaker-eu-central-1-106877348565/js-input/artmoca/artmoca_5.jpeg\n",
      "upload: img/artmoca_7.jpeg to s3://sagemaker-eu-central-1-106877348565/js-input/artmoca/artmoca_7.jpeg\n",
      "upload: img/artmoca_6.jpeg to s3://sagemaker-eu-central-1-106877348565/js-input/artmoca/artmoca_6.jpeg\n"
     ]
    }
   ],
   "source": [
    "DEFAULT_BUCKET = session.default_bucket()\n",
    "TRAIN_DATA_INPUT_PREFIX = 'js-input/artmoca/'\n",
    "TRAIN_DATA_INPUT_S3_PATH = f's3://{DEFAULT_BUCKET}/{TRAIN_DATA_INPUT_PREFIX}'\n",
    "!aws s3 cp ./img {TRAIN_DATA_INPUT_S3_PATH} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46e34ba6-879c-4ea1-90cc-128b0c526581",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image URI: 763104351884.dkr.ecr.eu-central-1.amazonaws.com/huggingface-pytorch-training:1.10.2-transformers4.17.0-gpu-py38-cu113-ubuntu20.04 \n",
      "Source URI: s3://jumpstart-cache-prod-eu-central-1/source-directory-tarballs/stabilityai/transfer_learning/txt2img/v1.0.3/sourcedir.tar.gz \n",
      "Model URI: s3://jumpstart-cache-prod-eu-central-1/stabilityai-training/train-model-txt2img-stabilityai-stable-diffusion-v2-1-base.tar.gz \n",
      "Output Storage: s3://sagemaker-eu-central-1-106877348565/js-output \n"
     ]
    }
   ],
   "source": [
    "MODEL_ID = 'model-txt2img-stabilityai-stable-diffusion-v2-1-base'\n",
    "MODEL_VERSION = '*' \n",
    "IMG_SCOPE = 'training'\n",
    "TRAIN_INSTANCE_TYPE = 'ml.g4dn.2xlarge'\n",
    "\n",
    "\n",
    "train_image_uri = image_uris.retrieve(\n",
    "    region=REGION, \n",
    "    framework=None,\n",
    "    model_id=MODEL_ID, \n",
    "    model_version=MODEL_VERSION, \n",
    "    image_scope=IMG_SCOPE, \n",
    "    instance_type=TRAIN_INSTANCE_TYPE\n",
    ")\n",
    "\n",
    "train_source_uri = script_uris.retrieve(\n",
    "    model_id=MODEL_ID, \n",
    "    model_version=MODEL_VERSION,\n",
    "    script_scope=IMG_SCOPE\n",
    ")\n",
    "\n",
    "\n",
    "train_model_uri = model_uris.retrieve(\n",
    "    model_id=MODEL_ID, \n",
    "    model_version=MODEL_VERSION, \n",
    "    model_scope=IMG_SCOPE\n",
    ")\n",
    "\n",
    "TRAIN_DATA_OUTPUT_PREFIX = 'js-output'\n",
    "TRAIN_DATA_OUTPUT_S3_PATH = f's3://{DEFAULT_BUCKET}/{TRAIN_DATA_OUTPUT_PREFIX}'\n",
    "\n",
    "print( \"Image URI: {} \".format(train_image_uri))\n",
    "print( \"Source URI: {} \".format(train_source_uri))\n",
    "print( \"Model URI: {} \".format(train_model_uri))\n",
    "print( \"Output Storage: {} \".format(TRAIN_DATA_OUTPUT_S3_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dda8c56e-4545-456e-9216-e33a8b639082",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': '20',\n",
       " 'max_steps': '400',\n",
       " 'batch_size': '1',\n",
       " 'with_prior_preservation': 'False',\n",
       " 'num_class_images': '100',\n",
       " 'learning_rate': '2e-06',\n",
       " 'prior_loss_weight': '1.0',\n",
       " 'center_crop': 'False',\n",
       " 'lr_scheduler': 'constant',\n",
       " 'adam_weight_decay': '0.01',\n",
       " 'adam_beta1': '0.9',\n",
       " 'adam_beta2': '0.999',\n",
       " 'adam_epsilon': '1e-08',\n",
       " 'gradient_accumulation_steps': '1',\n",
       " 'max_grad_norm': '1.0',\n",
       " 'compute_fid': 'False',\n",
       " 'seed': '0'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparams = hyperparameters.retrieve_default(\n",
    "    model_id=MODEL_ID, \n",
    "    model_version=MODEL_VERSION\n",
    ")\n",
    "\n",
    "hyperparams['max_steps'] = '400'\n",
    "# hyperparams['seed'] = '123'\n",
    "# hyperparams['with_prior_preservation'] = 'True'\n",
    "hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7147665c-a159-446e-8c16-e82ed5ee7592",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: genai-paris-avatar-model-txt2img-stabil-2023-04-03-23-39-53-809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2023-04-03 23:39:53 Starting - Starting the training job......\n",
      "2023-04-03 23:40:29 Starting - Preparing the instances for training..."
     ]
    }
   ],
   "source": [
    "MAX_RUN = 360000\n",
    "\n",
    "model_prefix = name_from_base(f'genai-paris-avatar-{MODEL_ID}-')\n",
    "training_job_name = f'{model_prefix}-finetuning'\n",
    "\n",
    "estimator = Estimator(\n",
    "    role=ROLE, \n",
    "    image_uri=train_image_uri, \n",
    "    source_dir=train_source_uri, \n",
    "    model_uri=train_model_uri, \n",
    "    entry_point='transfer_learning.py', \n",
    "    instance_count=1, \n",
    "    instance_type=TRAIN_INSTANCE_TYPE, \n",
    "    max_run=MAX_RUN, \n",
    "    hyperparameters=hyperparams, \n",
    "    output_path=TRAIN_DATA_OUTPUT_S3_PATH, \n",
    "    base_job_name=training_job_name\n",
    ")\n",
    "\n",
    "estimator.fit({'training': TRAIN_DATA_INPUT_S3_PATH}, logs=False)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-central-1:936697816551:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
